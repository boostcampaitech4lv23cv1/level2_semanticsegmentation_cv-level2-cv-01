{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "categories = {\n",
    "    1: 'General trash',\n",
    "    2: 'Paper',\n",
    "    3: 'Paper pack',\n",
    "    4: 'Metal',\n",
    "    5: 'Glass',\n",
    "    6: 'Plastic',\n",
    "    7: 'Styrofoam',\n",
    "    8: 'Plastic bag',\n",
    "    9: 'Battery',\n",
    "    10: 'Clothing'\n",
    "}\n",
    "\n",
    "data_dir = '/opt/ml/input/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plastic bag 7643\n",
      "Plastic 3090\n",
      "Glass 610\n",
      "General trash 2782\n",
      "Metal 562\n",
      "Paper 9311\n",
      "Paper pack 659\n",
      "Styrofoam 1343\n",
      "Clothing 177\n",
      "Battery 63\n"
     ]
    }
   ],
   "source": [
    "# 추출할 json 경로 지정\n",
    "file_name = 'train_all.json' #########지정해줄꺼 1##########\n",
    "target_dir = data_dir + '/' + file_name\n",
    "\n",
    "result = defaultdict(list)\n",
    "target_json = json.load(open(target_dir))\n",
    "\n",
    "# annotation과 클래스 추출\n",
    "for info in target_json['annotations']:\n",
    "    \n",
    "    category_id = info['category_id']\n",
    "    area = info['area']\n",
    "\n",
    "    result[categories[category_id]].append(area)\n",
    "\n",
    "# result 값 확인\n",
    "for k,v in result.items():\n",
    "    result[k].sort()\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plastic bag [2482, 10254]\n",
      "Plastic [648, 2429]\n",
      "Glass [1581, 7892]\n",
      "General trash [365, 1397]\n",
      "Metal [965, 6430]\n",
      "Paper [892, 4066]\n",
      "Paper pack [560, 2216]\n",
      "Styrofoam [2210, 6626]\n",
      "Clothing [3102, 18218]\n",
      "Battery [4365, 5834]\n"
     ]
    }
   ],
   "source": [
    "# cut: 클래스별 0.3, 0.6 quantile 계산 후 저장\n",
    "cut = defaultdict(list)\n",
    "\n",
    "for k in list(result.keys()):\n",
    "    cut[k].append(round(pd.Series(result[k]).quantile(.3)))\n",
    "    cut[k].append(round(pd.Series(result[k]).quantile(.6)))\n",
    "for k,v in cut.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.99s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "train0 2622\n",
      "test0 649\n",
      "train1 2616\n",
      "test1 655\n",
      "train2 2619\n",
      "test2 652\n",
      "train3 2611\n",
      "test3 660\n",
      "train4 2616\n",
      "test4 655\n"
     ]
    }
   ],
   "source": [
    "file_name = 'train_all.json' #########지정해줄꺼 1##########\n",
    "target_dir = data_dir + '/' + file_name\n",
    "target_coco = COCO(target_dir)\n",
    "var = [[target_coco.loadImgs(info['image_id'])[0]['file_name'], info['category_id'], info['area']] for info in target_json['annotations']]\n",
    "\n",
    "for i, (file_name, cat_id, area) in enumerate(var):\n",
    "    if area>cut[categories[cat_id]][1]:\n",
    "        var[i][1] += 20\n",
    "    elif area>cut[categories[cat_id]][0]:\n",
    "        var[i][1] += 10\n",
    "\n",
    "X = np.array([v[0] for v in var])\n",
    "y = np.array([v[1] for v in var])\n",
    "groups = np.array([v[0] for v in var])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "fold_names = dict()\n",
    "print()\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X, y, groups)):\n",
    "    train_names = set(groups[train_idx])\n",
    "    test_names = set(groups[test_idx])\n",
    "    fold_names[f'train{i}'] = train_names\n",
    "    fold_names[f'test{i}'] = test_names\n",
    "    #print(\"Train:\", len(train_names))\n",
    "    #print(\"     :\", y[train_idx])\n",
    "    #print(\"test:\", len(set(groups[test_idx])))\n",
    "    #print(\"     :\", y[test_idx])\n",
    "\n",
    "for k,v in fold_names.items():\n",
    "    print(k,len(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.47s)\n",
      "creating index...\n",
      "index created!\n",
      "기존 이미지 개수 = 3272\n",
      "기존 annotation 개수 = 26240\n",
      "시작 img 인덱스 = 0\n",
      "시작 anno 인덱스 = 0\n",
      "마지막 img 인덱스 = 2617\n",
      "마지막 anno 인덱스 = 21109\n",
      "삭제된 이미지 개수 = 655\n",
      "삭제된 annotation 개수 = 5117\n",
      "작아서 삭제된 annotation 개수 = 14\n",
      "변경 후 이미지 개수 = 2617\n",
      "변경 후 annotation 개수 = 21109\n"
     ]
    }
   ],
   "source": [
    "# 원하는 fold 저장\n",
    "\n",
    "data_dir = '/opt/ml/input/data'\n",
    "\n",
    "# 변경할 json 경로 지정\n",
    "file_name = 'train_all_sorted.json'\n",
    "target_dir = data_dir + '/' + file_name\n",
    "remove_thr = 16\n",
    "\n",
    "# 제거할 이미지 파일명 추가: ######### train1저장시 test1 제거, test1저장시 train1 제거 ##########\n",
    "exclude = set(fold_names['test4'])\n",
    "\n",
    "\n",
    "target_json = json.load(open(target_dir))\n",
    "target_coco = COCO(target_dir)\n",
    "print(f'기존 이미지 개수 = {len(target_json[\"images\"])}')\n",
    "print(f'기존 annotation 개수 = {len(target_json[\"annotations\"])}')\n",
    "\n",
    "# 새 json 객체 생성\n",
    "new_json = {\n",
    "    'info': target_json['info'],\n",
    "    'licenses': target_json['licenses'],\n",
    "    'images': [],\n",
    "    'categories': target_json['categories'],\n",
    "    'annotations': [],\n",
    "}\n",
    "\n",
    "img_idx = 0 # img 인덱스 -> 순서대로 0부터 1씩 증가해야함\n",
    "anno_idx = 0 # ann 인덱스 -> 이미지 상관없이 순서대로 0부터 1씩 증가해야함\n",
    "print(f'시작 img 인덱스 = {img_idx}')\n",
    "print(f'시작 anno 인덱스 = {anno_idx}')\n",
    "removed_annos_cnt = 0\n",
    "small_removed_annos_cnt = 0\n",
    "for i in range(len(target_json['images'][:])):\n",
    "    \n",
    "    img_id = target_coco.getImgIds(imgIds=i)\n",
    "    img_info = target_coco.loadImgs(img_id)[0]\n",
    "    img_name = img_info['file_name']\n",
    "    \n",
    "    if img_name in exclude:\n",
    "        ann_ids = target_coco.getAnnIds(imgIds=img_info['id'])\n",
    "        anns = target_coco.loadAnns(ann_ids)\n",
    "        removed_annos_cnt += len(anns)\n",
    "        continue\n",
    "\n",
    "    ann_ids = target_coco.getAnnIds(imgIds=img_info['id'])\n",
    "    anns = target_coco.loadAnns(ann_ids)\n",
    "    anns.sort(key=lambda ann:ann['area'], reverse=True) # area 큰 순\n",
    "\n",
    "    new_json['images'].append(\n",
    "        {\n",
    "            'license':0,\n",
    "            'url': None,\n",
    "            'file_name': img_name,\n",
    "            'height': 512,\n",
    "            'width': 512,\n",
    "            'date_captured': None,\n",
    "            'id': img_idx,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    for ann in anns:\n",
    "        ann['id'] = anno_idx\n",
    "        ann['image_id'] = img_idx\n",
    "\n",
    "        if ann['area'] < remove_thr:\n",
    "            small_removed_annos_cnt += 1\n",
    "            continue\n",
    "\n",
    "        anno_idx += 1\n",
    "        new_json['annotations'].append(ann)\n",
    "\n",
    "    img_idx += 1\n",
    "\n",
    "print(f'마지막 img 인덱스 = {img_idx}')\n",
    "print(f'마지막 anno 인덱스 = {anno_idx}')\n",
    "\n",
    "print(f'삭제된 이미지 개수 = {len(exclude)}')\n",
    "print(f'삭제된 annotation 개수 = {removed_annos_cnt}')\n",
    "\n",
    "print(f'작아서 삭제된 annotation 개수 = {small_removed_annos_cnt}')\n",
    "\n",
    "print(f'변경 후 이미지 개수 = {len(new_json[\"images\"])}')\n",
    "print(f'변경 후 annotation 개수 = {len(new_json[\"annotations\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.44s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "save_path = os.path.join(data_dir,f'{file_name.split(\".\")[0]}_train4.json')\n",
    "\n",
    "with open(save_path,'w') as f:\n",
    "        json.dump(new_json, f, indent=4)\n",
    "\n",
    "# coco 포멧 맞는지 확인\n",
    "demo = COCO(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold의 train과 val의 중복되는 이미지 확인 & 총 이미지 수 확인 후 기존 이미지 수와 비교: 3272\n",
    "train_dir = '/opt/ml/input/data/train_all_sorted_train4.json'\n",
    "val_dir = '/opt/ml/input/data/train_all_sorted_val4.json'\n",
    "\n",
    "t_json = json.load(open(train_dir))\n",
    "v_json = json.load(open(val_dir))\n",
    "t_names = set([info['file_name'] for info in t_json['images']])\n",
    "v_names = set([info['file_name'] for info in v_json['images']])\n",
    "\n",
    "t_names & v_names, len(t_names)+len(v_names), len(json.load(open('/opt/ml/input/data/train_all_sorted.json'))['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1968\n",
      "1971\n",
      "1963\n",
      "1968\n"
     ]
    }
   ],
   "source": [
    "# fold0과 나머지 fold의 겹치는 이미지 개수 확인\n",
    "t0_dir = '/opt/ml/input/data/fold5/train_all_sorted_train0.json'\n",
    "t1_dir = '/opt/ml/input/data/fold5/train_all_sorted_train1.json'\n",
    "t2_dir = '/opt/ml/input/data/fold5/train_all_sorted_train2.json'\n",
    "t3_dir = '/opt/ml/input/data/fold5/train_all_sorted_train3.json'\n",
    "t4_dir = '/opt/ml/input/data/fold5/train_all_sorted_train4.json'\n",
    "\n",
    "\n",
    "t0_names = set([info['file_name'] for info in json.load(open(t0_dir))['images']])\n",
    "t1_names = set([info['file_name'] for info in json.load(open(t1_dir))['images']])\n",
    "t2_names = set([info['file_name'] for info in json.load(open(t2_dir))['images']])\n",
    "t3_names = set([info['file_name'] for info in json.load(open(t3_dir))['images']])\n",
    "t4_names = set([info['file_name'] for info in json.load(open(t4_dir))['images']])\n",
    "\n",
    "print(len(t0_names & t1_names & t2_names & t3_names & t4_names))\n",
    "print(len(t0_names & t1_names))\n",
    "print(len(t0_names & t2_names))\n",
    "print(len(t0_names & t3_names))\n",
    "print(len(t0_names & t4_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36b65445d9ce5ce20025699eca542af702a8257f60b7fe337a56c3263cd17b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
